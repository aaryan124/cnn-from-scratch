# Neural Networks from Scratch (NumPy)

This repository contains core deep learning architectures â€” **RNN**, **LSTM**, and **CNN** â€” implemented completely from scratch using **NumPy**, without any deep learning libraries.

ğŸ§  Built for learning purposes.  
ğŸ“š Project purpose: To study and understand the internals of deep learning models through hands-on implementation.

---

## ğŸ“¦ Architectures Included

### ğŸ” RNN (Recurrent Neural Network)
- Basic sequence model using `tanh` activation
- Forward and Backward Pass (Backpropagation Through Time)
- Designed for character or sequence prediction

### ğŸ§  LSTM (Long Short-Term Memory)
- Handles long-term dependencies better than RNN
- Includes Forget, Input, Candidate, and Output gates
- Manual gradient computation

### ğŸ§± CNN (Convolutional Neural Network)
- 2D Convolution Layer (with padding and stride)
- MaxPooling
- Fully Connected (Dense) Layers
- ReLU and Softmax activations
- Cross-entropy loss
---
