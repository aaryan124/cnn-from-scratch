# Neural Networks from Scratch (NumPy)

This repository contains core deep learning architectures — **RNN**, **LSTM**, and **CNN** — implemented completely from scratch using **NumPy**, without any deep learning libraries.

🧠 Built for learning purposes.  
📚 Project purpose: To study and understand the internals of deep learning models through hands-on implementation.

---

## 📦 Architectures Included

### 🔁 RNN (Recurrent Neural Network)
- Basic sequence model using `tanh` activation
- Forward and Backward Pass (Backpropagation Through Time)
- Designed for character or sequence prediction

### 🧠 LSTM (Long Short-Term Memory)
- Handles long-term dependencies better than RNN
- Includes Forget, Input, Candidate, and Output gates
- Manual gradient computation

### 🧱 CNN (Convolutional Neural Network)
- 2D Convolution Layer (with padding and stride)
- MaxPooling
- Fully Connected (Dense) Layers
- ReLU and Softmax activations
- Cross-entropy loss
---
